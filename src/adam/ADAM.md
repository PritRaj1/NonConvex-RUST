# Adam

Adam is a stochastic gradient descent method that uses adaptive learning rates for each parameter.

## Sources and further information

- [Adam](https://arxiv.org/abs/1412.6980)